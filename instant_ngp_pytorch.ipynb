{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "instant_ngp_pytorch.ipynb",
   "private_outputs": true,
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLbV-a4CKw1t"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVlabs/tiny-cuda-nn.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install flip"
   ],
   "metadata": {
    "id": "MKo_pvhEQ13Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch"
   ],
   "metadata": {
    "id": "ejxo5tYOPag0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available()\n",
    "device = \"cuda\"\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "id": "Fp7RsG8aPhvZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir data\n",
    "!wget -P data --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=18JxhpWD-4ZmuFKLzKlAw-w5PpzZxXOcG' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=18JxhpWD-4ZmuFKLzKlAw-w5PpzZxXOcG\" -O nerf_synthetic.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip nerf_synthetic.zip -d data"
   ],
   "metadata": {
    "id": "_kYvKRXJU_FB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json \n",
    "import tinycudann as tcnn\n",
    "import torch\n",
    "\n",
    "with open(\"/content/tiny-cuda-nn/data/config_hash.json\") as f:\n",
    "\tconfig = json.load(f)\n",
    "\n",
    "# Option 1: efficient Encoding+Network combo.\n",
    "model = tcnn.NetworkWithInputEncoding(\n",
    "\t3, 128,\n",
    "\tconfig[\"encoding\"], config[\"network\"]\n",
    ")\n",
    "\n",
    "# Option 2: separate modules. Slower but more flexible.\n",
    "#encoding = tcnn.Encoding(72, config[\"encoding\"])\n",
    "#network = tcnn.Network(encoding.n_output_dims, 128, config[\"network\"])\n",
    "#model = torch.nn.Sequential(encoding, network)"
   ],
   "metadata": {
    "id": "VsVr3IWqiVb5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Copyright (c) 2020-2022, NVIDIA CORPORATION.  All rights reserved.\n",
    "# \n",
    "# Redistribution and use in source and binary forms, with or without modification, are permitted\n",
    "# provided that the following conditions are met:\n",
    "#     * Redistributions of source code must retain the above copyright notice, this list of\n",
    "#       conditions and the following disclaimer.\n",
    "#     * Redistributions in binary form must reproduce the above copyright notice, this list of\n",
    "#       conditions and the following disclaimer in the documentation and/or other materials\n",
    "#       provided with the distribution.\n",
    "#     * Neither the name of the NVIDIA CORPORATION nor the names of its contributors may be used\n",
    "#       to endorse or promote products derived from this software without specific prior written\n",
    "#       permission.\n",
    "# \n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR\n",
    "# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n",
    "# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n",
    "# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "# STRICT LIABILITY, OR TOR (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "\n",
    "ROOT_DIR = \"/content/tiny-cuda-nn/\"\n",
    "\n",
    "def mse2psnr(x):\n",
    "\treturn -10.*np.log(x)/np.log(10.)\n",
    "\n",
    "def write_image_imageio(img_file, img, quality):\n",
    "\timg = (np.clip(img, 0.0, 1.0) * 255.0 + 0.5).astype(np.uint8)\n",
    "\tkwargs = {}\n",
    "\tif os.path.splitext(img_file)[1].lower() in [\".jpg\", \".jpeg\"]:\n",
    "\t\tif img.ndim >= 3 and img.shape[2] > 3:\n",
    "\t\t\timg = img[:,:,:3]\n",
    "\t\tkwargs[\"quality\"] = quality\n",
    "\t\tkwargs[\"subsampling\"] = 0\n",
    "\timageio.imwrite(img_file, img, **kwargs)\n",
    "\n",
    "def read_image_imageio(img_file):\n",
    "\timg = imageio.imread(img_file)\n",
    "\timg = np.asarray(img).astype(np.float32)\n",
    "\tif len(img.shape) == 2:\n",
    "\t\timg = img[:,:,np.newaxis]\n",
    "\treturn img / 255.0\n",
    "\n",
    "def srgb_to_linear(img):\n",
    "\tlimit = 0.04045\n",
    "\treturn np.where(img > limit, np.power((img + 0.055) / 1.055, 2.4), img / 12.92)\n",
    "\n",
    "def linear_to_srgb(img):\n",
    "\tlimit = 0.0031308\n",
    "\treturn np.where(img > limit, 1.055 * (img ** (1.0 / 2.4)) - 0.055, 12.92 * img)\n",
    "\n",
    "def read_image(file):\n",
    "\tif os.path.splitext(file)[1] == \".bin\":\n",
    "\t\twith open(file, \"rb\") as f:\n",
    "\t\t\tbytes = f.read()\n",
    "\t\t\th, w = struct.unpack(\"ii\", bytes[:8])\n",
    "\t\t\timg = np.frombuffer(bytes, dtype=np.float16, count=h*w*4, offset=8).astype(np.float32).reshape([h, w, 4])\n",
    "\telse:\n",
    "\t\timg = read_image_imageio(file)\n",
    "\t\tif img.shape[2] == 4:\n",
    "\t\t\timg[...,0:3] = srgb_to_linear(img[...,0:3])\n",
    "\t\t\t# Premultiply alpha\n",
    "\t\t\timg[...,0:3] *= img[...,3:4]\n",
    "\t\telse:\n",
    "\t\t\timg = srgb_to_linear(img)\n",
    "\treturn img\n",
    "\n",
    "def write_image(file, img, quality=95):\n",
    "\tif os.path.splitext(file)[1] == \".bin\":\n",
    "\t\tif img.shape[2] < 4:\n",
    "\t\t\timg = np.dstack((img, np.ones([img.shape[0], img.shape[1], 4 - img.shape[2]])))\n",
    "\t\twith open(file, \"wb\") as f:\n",
    "\t\t\tf.write(struct.pack(\"ii\", img.shape[0], img.shape[1]))\n",
    "\t\t\tf.write(img.astype(np.float16).tobytes())\n",
    "\telse:\n",
    "\t\tif img.shape[2] == 4:\n",
    "\t\t\timg = np.copy(img)\n",
    "\t\t\t# Unmultiply alpha\n",
    "\t\t\timg[...,0:3] = np.divide(img[...,0:3], img[...,3:4], out=np.zeros_like(img[...,0:3]), where=img[...,3:4] != 0)\n",
    "\t\t\timg[...,0:3] = linear_to_srgb(img[...,0:3])\n",
    "\t\telse:\n",
    "\t\t\timg = linear_to_srgb(img)\n",
    "\t\twrite_image_imageio(file, img, quality)\n",
    "\n",
    "def trim(error, skip=0.000001):\n",
    "\terror = np.sort(error.flatten())\n",
    "\tsize = error.size\n",
    "\tskip = int(skip * size)\n",
    "\treturn error[skip:size-skip].mean()\n",
    "\n",
    "def luminance(a):\n",
    "\ta = np.maximum(0, a)**0.4545454545\n",
    "\treturn 0.2126 * a[:,:,0] + 0.7152 * a[:,:,1] + 0.0722 * a[:,:,2]\n",
    "\n",
    "def L1(img, ref):\n",
    "\treturn np.abs(img - ref)\n",
    "\n",
    "def APE(img, ref):\n",
    "\treturn L1(img, ref) / (1e-2 + ref)\n",
    "\n",
    "def SAPE(img, ref):\n",
    "\treturn L1(img, ref) / (1e-2 + (ref + img) / 2.)\n",
    "\n",
    "def L2(img, ref):\n",
    "\treturn (img - ref)**2\n",
    "\n",
    "def RSE(img, ref):\n",
    "\treturn L2(img, ref) / (1e-2 + ref**2)\n",
    "\n",
    "def rgb_mean(img):\n",
    "\treturn np.mean(img, axis=2)\n",
    "\n",
    "def compute_error_img(metric, img, ref):\n",
    "\timg[np.logical_not(np.isfinite(img))] = 0\n",
    "\timg = np.maximum(img, 0.)\n",
    "\tif metric == \"MAE\":\n",
    "\t\treturn L1(img, ref)\n",
    "\telif metric == \"MAPE\":\n",
    "\t\treturn APE(img, ref)\n",
    "\telif metric == \"SMAPE\":\n",
    "\t\treturn SAPE(img, ref)\n",
    "\telif metric == \"MSE\":\n",
    "\t\treturn L2(img, ref)\n",
    "\telif metric == \"MScE\":\n",
    "\t\treturn L2(np.clip(img, 0.0, 1.0), np.clip(ref, 0.0, 1.0))\n",
    "\telif metric == \"MRSE\":\n",
    "\t\treturn RSE(img, ref)\n",
    "\telif metric == \"MtRSE\":\n",
    "\t\treturn trim(RSE(img, ref))\n",
    "\telif metric == \"MRScE\":\n",
    "\t\treturn RSE(np.clip(img, 0, 100), np.clip(ref, 0, 100))\n",
    "\n",
    "\traise ValueError(f\"Unknown metric: {metric}.\")\n",
    "\n",
    "def compute_error(metric, img, ref):\n",
    "\tmetric_map = compute_error_img(metric, img, ref)\n",
    "\tmetric_map[np.logical_not(np.isfinite(metric_map))] = 0\n",
    "\tif len(metric_map.shape) == 3:\n",
    "\t\tmetric_map = np.mean(metric_map, axis=2)\n",
    "\tmean = np.mean(metric_map)\n",
    "\treturn mean"
   ],
   "metadata": {
    "id": "E_F8-k7PlI04"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Copyright (c) 2020-2022, NVIDIA CORPORATION.  All rights reserved.\n",
    "# \n",
    "# Redistribution and use in source and binary forms, with or without modification, are permitted\n",
    "# provided that the following conditions are met:\n",
    "#     * Redistributions of source code must retain the above copyright notice, this list of\n",
    "#       conditions and the following disclaimer.\n",
    "#     * Redistributions in binary form must reproduce the above copyright notice, this list of\n",
    "#       conditions and the following disclaimer in the documentation and/or other materials\n",
    "#       provided with the distribution.\n",
    "#     * Neither the name of the NVIDIA CORPORATION nor the names of its contributors may be used\n",
    "#       to endorse or promote products derived from this software without specific prior written\n",
    "#       permission.\n",
    "# \n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR\n",
    "# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n",
    "# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n",
    "# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "# STRICT LIABILITY, OR TOR (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "#         using tiny-cuda-nn's PyTorch extension. Runs ~2x slower than native.\n",
    "\n",
    "import argparse\n",
    "import  json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "\n",
    "try:\n",
    "\timport tinycudann as tcnn\n",
    "except ImportError:\n",
    "\tprint(\"This sample requires the tiny-cuda-nn extension for PyTorch.\")\n",
    "\tprint(\"You can install it by running:\")\n",
    "\tprint(\"============================================================\")\n",
    "\tprint(\"tiny-cuda-nn$ cd bindings/torch\")\n",
    "\tprint(\"tiny-cuda-nn/bindings/torch$ python setup.py install\")\n",
    "\tprint(\"============================================================\")\n",
    "\tsys.exit()\n",
    "\n",
    "SCRIPTS_DIR = os.path.join(ROOT_DIR, \"scripts\")\n",
    "sys.path.insert(0, SCRIPTS_DIR)\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "class Image(torch.nn.Module):\n",
    "\tdef __init__(self, filename, device):\n",
    "\t\tsuper(Image, self).__init__()\n",
    "\t\tself.data = torch.from_numpy(read_image(filename)).float().to(device)\n",
    "\n",
    "\tdef forward(self, xs):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# Bilinearly filtered lookup from the image. Not super fast,\n",
    "\t\t\t# but less than ~20% of the overall runtime of this example.\n",
    "\t\t\tshape = self.data.shape\n",
    "\n",
    "\t\t\txs = xs * torch.tensor([shape[1], shape[0]], device=xs.device).float()\n",
    "\t\t\tindices = xs.long()\n",
    "\t\t\tlerp_weights = xs - indices.float()\n",
    "\n",
    "\t\t\tx0 = indices[:, 0].clamp(min=0, max=shape[1]-1)\n",
    "\t\t\ty0 = indices[:, 1].clamp(min=0, max=shape[0]-1)\n",
    "\t\t\tx1 = (x0 + 1).clamp(max=shape[1]-1)\n",
    "\t\t\ty1 = (y0 + 1).clamp(max=shape[0]-1)\n",
    "\n",
    "\t\t\treturn (\n",
    "\t\t\t\tself.data[y0, x0] * (1.0 - lerp_weights[:,0:1]) * (1.0 - lerp_weights[:,1:2]) +\n",
    "\t\t\t\tself.data[y0, x1] * lerp_weights[:,0:1] * (1.0 - lerp_weights[:,1:2]) +\n",
    "\t\t\t\tself.data[y1, x0] * (1.0 - lerp_weights[:,0:1]) * lerp_weights[:,1:2] +\n",
    "\t\t\t\tself.data[y1, x1] * lerp_weights[:,0:1] * lerp_weights[:,1:2]\n",
    "\t\t\t)\n",
    "\n",
    "def get_args():\n",
    "\tparser = argparse.ArgumentParser(description=\"Image benchmark using PyTorch bindings.\")\n",
    "\n",
    "\tparser.add_argument(\"image\", nargs=\"?\", default=\"data/images/albert.jpg\", help=\"Image to match\")\n",
    "\tparser.add_argument(\"config\", nargs=\"?\", default=\"data/config_hash.json\", help=\"JSON config for tiny-cuda-nn\")\n",
    "\tparser.add_argument(\"n_steps\", nargs=\"?\", type=int, default=10000000, help=\"Number of training steps\")\n",
    "\tparser.add_argument(\"result_filename\", nargs=\"?\", default=\"\", help=\"Number of training steps\")\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\treturn args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tprint(\"================================================================\")\n",
    "\tprint(\"This script replicates the behavior of the native CUDA example  \")\n",
    "\tprint(\"mlp_learning_an_image.cu using tiny-cuda-nn's PyTorch extension.\")\n",
    "\tprint(\"This extension >> runs ~2x slower than native << as of now.     \")\n",
    "\tprint(\"================================================================\")\n",
    "\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "\t#args = get_args()\n",
    "\n",
    "\twith open(\"/content/tiny-cuda-nn/data/config_hash.json\") as config_file:\n",
    "\t\tconfig = json.load(config_file)\n",
    "\n",
    "\timage = Image(\"/content/data/nerf_synthetic/lego/train/r_0.png\", device)\n",
    "\tn_channels = image.data.shape[2]\n",
    "\n",
    "\tmodel = tcnn.NetworkWithInputEncoding(n_input_dims=2, n_output_dims=n_channels, encoding_config=config[\"encoding\"], network_config=config[\"network\"])\n",
    "\tprint(model)\n",
    "\n",
    "\t#===================================================================================================\n",
    "\t# The following is equivalent to the above, but slower. Only use \"naked\" tcnn.Encoding and\n",
    "\t# tcnn.Network when you don't want to combine them. Otherwise, use tcnn.NetworkWithInputEncoding.\n",
    "\t#===================================================================================================\n",
    "\t# encoding = tcnn.Encoding(n_input_dims=2, encoding_config=config[\"encoding\"])\n",
    "\t# network = tcnn.Network(n_input_dims=encoding.n_output_dims, n_output_dims=n_channels, network_config=config[\"network\"])\n",
    "\t# model = torch.nn.Sequential(encoding, network)\n",
    "\n",
    "\toptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\t# Variables for saving/displaying image results\n",
    "\tresolution = image.data.shape[0:2]\n",
    "\timg_shape = resolution + torch.Size([image.data.shape[2]])\n",
    "\tn_pixels = resolution[0] * resolution[1]\n",
    "\n",
    "\thalf_dx =  0.5 / resolution[0]\n",
    "\thalf_dy =  0.5 / resolution[1]\n",
    "\txs = torch.linspace(half_dx, 1-half_dx, resolution[0], device=device)\n",
    "\tys = torch.linspace(half_dx, 1-half_dx, resolution[1], device=device)\n",
    "\txv, yv = torch.meshgrid([xs, ys], indexing=\"ij\")\n",
    "\n",
    "\txy = torch.stack((yv.flatten(), xv.flatten())).t()\n",
    "\n",
    "\tpath = f\"reference.jpg\"\n",
    "\tprint(f\"Writing '{path}'... \", end=\"\")\n",
    "\twrite_image(path, image(xy).reshape(img_shape).detach().cpu().numpy())\n",
    "\tprint(\"done.\")\n",
    "\n",
    "\tprev_time = time.time()\n",
    "\n",
    "\tbatch_size = 2**16\n",
    "\tinterval = 10\n",
    "\n",
    "\tprint(f\"Beginning optimization with {5000} training steps.\")\n",
    "\n",
    "\ttraced_image = torch.jit.trace(image, torch.rand([batch_size, 2], device=device, dtype=torch.float32))\n",
    "\n",
    "\tfor i in range(5000):\n",
    "\t\tbatch = torch.rand([batch_size, 2], device=device, dtype=torch.float32)\n",
    "\t\ttargets = traced_image(batch)\n",
    "\t\toutput = model(batch)\n",
    "\n",
    "\t\trelative_l2_error = (output - targets.to(output.dtype))**2 / (output.detach()**2 + 0.01)\n",
    "\t\tloss = relative_l2_error.mean()\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tif i % interval == 0:\n",
    "\t\t\tloss_val = loss.item()\n",
    "\t\t\ttorch.cuda.synchronize()\n",
    "\t\t\telapsed_time = time.time() - prev_time\n",
    "\t\t\tprint(f\"Step#{i}: loss={loss_val} time={int(elapsed_time*1000000)}[µs]\")\n",
    "\n",
    "\t\t\tpath = f\"{i}.jpg\"\n",
    "\t\t\tprint(f\"Writing '{path}'... \", end=\"\")\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\twrite_image(path, model(xy).reshape(img_shape).clamp(0.0, 1.0).detach().cpu().numpy())\n",
    "\t\t\tprint(\"done.\")\n",
    "\n",
    "\t\t\t# Ignore the time spent saving the image\n",
    "\t\t\tprev_time = time.time()\n",
    "\n",
    "\t\t\tif i > 0 and interval < 1000:\n",
    "\t\t\t\tinterval *= 10\n",
    "\n",
    "\tif \"result.jpg\":\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\twrite_image(\"result.jpg\", model(xy).reshape(img_shape).clamp(0.0, 1.0).detach().cpu().numpy())\n",
    "\t\tprint(\"done.\")"
   ],
   "metadata": {
    "id": "vr_kutFwkd25"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ASHAWKEY PYTORCH IMPLEMENTATION**"
   ],
   "metadata": {
    "id": "3Q6JFjsmMCQW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/ashawkey/torch-ngp.git"
   ],
   "metadata": {
    "id": "UgDcGrodPf8_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/NVlabs/instant-ngp.git"
   ],
   "metadata": {
    "id": "9nPzD9QzMW0e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "id": "zw9zRUvGSiTA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python main_nerf.py /content/instant-ngp/data/nerf/fox --workspace trial_nerf -O --gui"
   ],
   "metadata": {
    "id": "QrBCIKG0MvcT"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}